{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import librosa\n",
    "import numpy as np\n",
    "import os, shutil, subprocess\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, LSTM, Dense, Reshape, Activation, Dropout, Flatten\n",
    "from keras.models import Model\n",
    "from tqdm import tqdm\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import RMSprop,Adam\n",
    "#from keras.optimizers import RMSprop, Adam\n",
    "import h5py\n",
    "from keras.callbacks import TensorBoard\n",
    "import argparse, fnmatch\n",
    "import pickle\n",
    "import random\n",
    "import time, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\"--i\",\\n\"/mnt/hdd/eric/.tmp_ipy_d/make/TalkingFaceGeneration_Pytorch/output/eric_output.hdf5\",\\n\"--hid-unit\",\\n\"512\",\\n\"--d\",\\n\"1\",\\n\"--c\",\\n\"3\",\\n\"--o\",\\n\"/mnt/hdd/eric/.tmp_ipy_d/make/TalkingFaceGeneration_Pytorch/train_output\"\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "parser = argparse.ArgumentParser(description=__doc__)\n",
    "parser.add_argument(\"-i\", \"--in-file\", default=\"/mnt/hdd/eric/.tmp_ipy_d/make/TalkingFaceGeneration_Pytorch/output/eric_output.hdf5\",type=str, help=\"Input file containing train data\")\n",
    "parser.add_argument(\"-u\", \"--hid-unit\", default=512, type=int, help=\"hidden units\")\n",
    "\n",
    "# The amount of delay we introduce\n",
    "# is between 1 (40 ms) and 5 frames (200 ms).\n",
    "parser.add_argument(\"-d\", \"--delay\", default=1,type=int, help=\"Delay in terms of number of frames\")\n",
    "\n",
    "parser.add_argument(\"-c\", \"--ctx\", default=3,type=int, help=\"context window size\")\n",
    "# can find \"3\" in generator.py\n",
    "\n",
    "parser.add_argument(\"-o\", \"--out-fold\", default=\"/mnt/hdd/eric/.tmp_ipy_d/make/TalkingFaceGeneration_Pytorch/train_output\",type=str, help=\"output folder\")\n",
    "args = parser.parse_args([])\n",
    "\n",
    "'''\n",
    "\"--i\",\n",
    "\"/mnt/hdd/eric/.tmp_ipy_d/make/TalkingFaceGeneration_Pytorch/output/eric_output.hdf5\",\n",
    "\"--hid-unit\",\n",
    "\"512\",\n",
    "\"--d\",\n",
    "\"1\",\n",
    "\"--c\",\n",
    "\"3\",\n",
    "\"--o\",\n",
    "\"/mnt/hdd/eric/.tmp_ipy_d/make/TalkingFaceGeneration_Pytorch/train_output\"\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/hdd/eric/.tmp_ipy_d/make/TalkingFaceGeneration_Pytorch/train_output'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.out_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = args.out_fold+'_'+str(args.hid_unit)+'/'\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "else:\n",
    "    shutil.rmtree(output_path)\n",
    "    os.mkdir(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctxWin = args.ctx\n",
    "num_features_X = 128 * (ctxWin+1)# input feature size # 128 * 3 = 512\n",
    "num_features_Y = 136 # output feature size --> (68, 2)\n",
    "num_frames = 75 # time-steps\n",
    "batchsize = 128\n",
    "h_dim = args.hid_unit\n",
    "lr = 1e-3\n",
    "drpRate = 0.2 # Dropout rate \n",
    "recDrpRate = 0.2 # Recurrent Dropout rate \n",
    "frameDelay = args.delay # Time delay\n",
    "\n",
    "numEpochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "dset = h5py.File(args.in_file, 'r')\n",
    "\n",
    "numIt = int(dset['flmark'].shape[0]//batchsize) + 1\n",
    "metrics = ['MSE', 'MAE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['MelFeatures', 'flmark']>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch \n",
    "\n",
    "class Custom_Dataset(Dataset):\n",
    "    ''' torch version data pipeline '''\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data['MelFeatures'])\n",
    "    \n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        cur_lmark = self.data['flmark'][idx, :, :]\n",
    "        cur_mel = self.data['MelFeatures'][idx, :, :]\n",
    "        \n",
    "        def addContext(melSpc, ctxWin):\n",
    "            ctx = melSpc[:,:]\n",
    "            filler = melSpc[0, :]\n",
    "            for i in range(ctxWin):\n",
    "                melSpc = np.insert(melSpc, 0, filler, axis=0)[:ctx.shape[0], :]\n",
    "                ctx = np.append(ctx, melSpc, axis=1)\n",
    "            return ctx\n",
    "\n",
    "        if frameDelay > 0:\n",
    "            filler = np.tile(cur_lmark[0:1, :], [frameDelay, 1])\n",
    "            cur_lmark = np.insert(cur_lmark, 0, filler, axis=0)[:num_frames]\n",
    "        \n",
    "        X = addContext(cur_mel, ctxWin)\n",
    "        Y_= cur_lmark\n",
    "\n",
    "        out = {'cur_mel':torch.from_numpy(X), 'cur_lmark':torch.from_numpy(Y_)}\n",
    "        return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_dataset = Custom_Dataset(data=dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cur_mel': tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 3.9939,  2.7080,  2.9608,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [-1.5734, -1.0146,  0.6926,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 0.2623, -0.3484, -0.4165,  ..., -0.1854, -0.1593, -0.1499],\n",
       "         [-0.6610,  0.5725,  0.0415,  ...,  0.4424,  0.2738,  0.1941],\n",
       "         [-0.8899, -1.4737,  0.5270,  ..., -0.0752, -0.2463, -0.0744]]),\n",
       " 'cur_lmark': tensor([[0.1841, 0.3372, 0.1908,  ..., 0.7029, 0.4540, 0.6996],\n",
       "         [0.1841, 0.3372, 0.1908,  ..., 0.7029, 0.4540, 0.6996],\n",
       "         [0.1838, 0.3308, 0.1904,  ..., 0.7028, 0.4539, 0.6964],\n",
       "         ...,\n",
       "         [0.1869, 0.3370, 0.1908,  ..., 0.6834, 0.4615, 0.6769],\n",
       "         [0.1836, 0.3277, 0.1877,  ..., 0.6834, 0.4587, 0.6770],\n",
       "         [0.1838, 0.3308, 0.1877,  ..., 0.6802, 0.4587, 0.6770]])}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_dataset.__getitem__(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([75, 136])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_dataset.__getitem__(1)['cur_lmark'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<KeysViewHDF5 ['MelFeatures', 'flmark']>, 978)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset.keys(), dset['MelFeatures'].__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(lm_dataset, batch_size=128, \n",
    "                        shuffle=True, num_workers=4) #? batch_size 에 따라서, 왜 안바뀌지? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 75, 512])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataloader))[\"cur_mel\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 75, 136])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataloader))[\"cur_lmark\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---- build torch model \n",
    "import torch.nn as nn\n",
    "\n",
    "class AirModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm_1 = nn.LSTM(input_size=512, hidden_size=512, num_layers=3, batch_first=True)\n",
    "        # self.lstm_2 = nn.LSTM(input_size=512, hidden_size=512, batch_first=True)\n",
    "        # self.lstm_3 = nn.LSTM(input_size=512, hidden_size=512, batch_first=True)\n",
    "        self.lstm_4 = nn.LSTM(input_size=512, hidden_size=136, num_layers=1,batch_first=True)\n",
    "        # #self.linear = nn.Linear(50, 1)\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm_1(x)\n",
    "        # x, _ = self.lstm_2(x)\n",
    "        # x, _ = self.lstm_3(x)\n",
    "        x, _ = self.lstm_4(x)\n",
    "        # #x = self.linear(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AirModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(next(iter(train_dataloader))[\"cur_mel\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 75, 136])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5377535223960876\n",
      "0.1307123601436615\n",
      "0.08724506199359894\n",
      "0.07066360861063004\n",
      "0.0640668123960495\n",
      "0.05995002016425133\n",
      "0.05684724450111389\n",
      "0.05367538705468178\n",
      "0.0507766492664814\n",
      "0.04689768701791763\n",
      "0.04279610887169838\n",
      "0.03740498796105385\n",
      "0.033158231526613235\n",
      "0.02838161587715149\n",
      "0.02539215236902237\n",
      "0.021832067519426346\n",
      "0.020485321059823036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _releaseLock at 0x7f5f2e9388b0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/hdd/eric/.conda/envs/9.tmp/lib/python3.9/logging/__init__.py\", line 227, in _releaseLock\n",
      "    def _releaseLock():\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.018367191776633263\n",
      "0.017556913197040558\n",
      "0.01702919974923134\n",
      "0.04962783679366112\n",
      "0.014022758230566978\n",
      "0.01431606151163578\n",
      "0.013599080964922905\n",
      "0.01349638495594263\n",
      "0.048621855676174164\n",
      "0.01275260467082262\n",
      "0.013838053680956364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011175678111612797\n",
      "0.011615114286541939\n"
     ]
    }
   ],
   "source": [
    "# MSE and adam \n",
    "import torch.optim as optim\n",
    "device = \"cuda:0\"\n",
    "\n",
    "model = AirModel()\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "loader = train_dataloader\n",
    "\n",
    "n_epochs = 200 \n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    # train\n",
    "    for i,data_ in enumerate(loader):\n",
    "        x_train = data_[\"cur_mel\"].to(device)\n",
    "        y_train = data_[\"cur_lmark\"].to(device)\n",
    "        \n",
    "        y_pred = model(x_train)\n",
    "        loss   = loss_fn(y_pred, y_train)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % 20 ==0:\n",
    "            print(f\"{np.sqrt(loss.detach().cpu())}\")\n",
    "\n",
    "    # model save \n",
    "    if epoch % 10 ==0:\n",
    "        torch.save(model.state_dict(), os.path.join( args.out_fold, f\"{epoch}_model.pth\"))\n",
    "        \n",
    "        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "9.tmp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
